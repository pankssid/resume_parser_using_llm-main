{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P74Y1h786W1A",
        "outputId": "a4b6d5a3-31c8-4bf8-f3d4-8c67db91a150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /Users/macbook/anaconda3/lib/python3.11/site-packages (3.0.1)\n",
            "Collecting pypdf\n",
            "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/89/b4/c751015b8802bcd4f7705580ac5e84f01f1d09ca38f1cff6bf1ad680bc43/pypdf-3.16.4-py3-none-any.whl.metadata\n",
            "  Downloading pypdf-3.16.4-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: openai in /Users/macbook/anaconda3/lib/python3.11/site-packages (0.28.1)\n",
            "Requirement already satisfied: langchain in /Users/macbook/anaconda3/lib/python3.11/site-packages (0.0.310)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/macbook/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /Users/macbook/anaconda3/lib/python3.11/site-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
            "Requirement already satisfied: anyio<4.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (3.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.40 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.43)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (2.4.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/macbook/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
            "Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.16.4\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 pypdf openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cFBbWy1c6lTy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8yrXlCz6a93",
        "outputId": "9485cc4f-9ced-4e9f-97bb-90230fd250af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/macbook/anaconda3/lib/python3.11/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Compare the following Job Title and Responsibilities with the provided, Display the matching percentage of scores:\n",
            "\n",
            "Context:\n",
            "- In the field of Data Science, it's crucial to have a strong foundation in various algorithms and models.\n",
            "\n",
            "**Job Title:** Data Scientist (Machine Learning)\n",
            "\n",
            "**Responsibilities:**\n",
            "1. Develop and implement machine learning models for data analysis and predictive modeling.\n",
            "2. Collaborate with cross-functional teams to gather and analyze data, ensuring accuracy and relevance.\n",
            "3. Explore and apply advanced statistical techniques to derive actionable insights from large datasets.\n",
            "4. Continuously research and stay updated on the latest advancements in machine learning and data science.\n",
            "5. Communicate findings and recommendations to stakeholders in a clear and understandable manner.\n",
            "\n",
            "Format the answer in below YAML Format:\n",
            "---\n",
            "Total Experience: ''\n",
            "Matching Percentage of Score: ''\n",
            "\n",
            "Swapnil Shingate  \n",
            "Azure  Data  Engineer  \n",
            " \n",
            " \n",
            "Personal  Info  \n",
            " \n",
            "Email  \n",
            "shingateswap96@gmail.com  2.6 Years of total experience in which 1.8 Years as an Azure Data Engineer. \n",
            "Proficient in creating Data pipelines and data lakes on Azure. Strong Expertise in \n",
            "Azure  services, including Azure Data Factory, Azure Databricks, Azure SQL Data \n",
            "Warehouse, Azure Blob Storage, ADLS and Azure Synapse Analytics. Proficient in \n",
            "SQL and query optimization for data extraction, transformation, and loading. (ETL)  \n",
            " \n",
            " \n",
            " \n",
            "Work History  \n",
            " \n",
            "Phone  \n",
            "+918087223803  \n",
            " \n",
            "Certifications  \n",
            " \n",
            " \n",
            "Microsoft  Certified  \n",
            "AZ-900 Azure Fun damentals  \n",
            "AI-900 Azure AI Fundamentals  \n",
            "DP-900 Azure Data Fundamentals  \n",
            "DP-203 Azure Data Engineer  \n",
            "DP-100 Azure Data Scientist  \n",
            "DP-300 Azure RDBA  \n",
            "AI-102 Azure AI Engineer  \n",
            "AZ-104 Azure Administrator  \n",
            " \n",
            "AWS  Certified  \n",
            "CLF_C01 - AWS Cloud Practitioner  \n",
            " \n",
            " \n",
            "Languages  \n",
            " \n",
            " English  \n",
            " Marathi  \n",
            " Hindi  \n",
            " Japanese  \n",
            " \n",
            " \n",
            " \n",
            "Skills  \n",
            " \n",
            " Azure  Services  \n",
            "(Data Factory, ADLS Gen2, BLOB \n",
            "Storage)  \n",
            " Azure Databricks, Synapse \n",
            "Analytics  \n",
            " ETL/ELT Process.  \n",
            " Snowflake Cloud Warehouse.  \n",
            " Data Modeling, Python, SQL  \n",
            " Hadoop Framework  \n",
            "                                                                                                               \n",
            "Education  \n",
            " \n",
            " \n",
            "2017 -07 \n",
            "- 2020 -10 Mechanical Engineer , B.E. (Bachelors  of Engineering ) \n",
            " \n",
            "MMIT, Pune.  \n",
            " \n",
            "  \n",
            "2022 -04 \n",
            "   To Present  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "2020 -12 \n",
            "  To 2021 -11           Azure Data Engineer  \n",
            "     Infosys Ltd. Pune  \n",
            " Designed and Implemented data pipelines using Azure \n",
            "Data Factory to efficiently ingest, transform and load (ETL) \n",
            "data from various on premise sources into ADLS Gen2.  \n",
            " Optimized data storage and query performance by \n",
            "utilizing Azure Databricks and Azure Synapse Analytics.  \n",
            " Maintained Data security and compliance standards by \n",
            "implementing Azure Data Lake Storage access controls and \n",
            "encryption.  \n",
            " Strong  Expertise in Change Data Capture (CDC) tool \n",
            "Attunity/Qlik Replicate tool on Designing and \n",
            "Impleme nting Data Pipelines to ingest near real t ime data \n",
            "from various on premise sources to ADLS Gen2 and  \n",
            "Snowflake clou d data warehouse.  \n",
            " Troubleshooting near real time data replication Latency \n",
            "and Task performance Issues.  \n",
            " \n",
            "    IOT Data Engineer  \n",
            "      Thermax Ltd. Pune  \n",
            " Thermax ROSS  (Remote Online Service Support)  \n",
            "Developed ETL process using python and SQL to clean and \n",
            "transform Unstructured operational data coming from IOT \n",
            "sensors and devices mounted on Thermax Boilers and \n",
            "chillers as Part of Thermax ROSS.  \n",
            " Collaborated with cross -functional teams to gather data \n",
            "requirements and ensure data accuracy.  \n",
            " Monitor near real time data coming from IOT devices to \n",
            "predict operational parameters of Equipment.  \n",
            " Implemented data quality checks and monitoring \n",
            "solutions to proactively id entify data issue.  \n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Compare the following Job Title and Responsibilities with the provided, Display the matching percentage of scores:\n",
            "\n",
            "Context:\n",
            "- In the field of Data Science, it's crucial to have a strong foundation in various algorithms and models.\n",
            "\n",
            "**Job Title:** Data Scientist (Machine Learning)\n",
            "\n",
            "**Responsibilities:**\n",
            "1. Develop and implement machine learning models for data analysis and predictive modeling.\n",
            "2. Collaborate with cross-functional teams to gather and analyze data, ensuring accuracy and relevance.\n",
            "3. Explore and apply advanced statistical techniques to derive actionable insights from large datasets.\n",
            "4. Continuously research and stay updated on the latest advancements in machine learning and data science.\n",
            "5. Communicate findings and recommendations to stakeholders in a clear and understandable manner.\n",
            "\n",
            "Format the answer in below YAML Format:\n",
            "---\n",
            "Total Experience: ''\n",
            "Matching Percentage of Score: ''\n",
            "\n",
            "Omkar Pathak\n",
            "SOFTWAREENGINEER · FULLSTACKPYTHONDEVELOPER\n",
            "Pune, Maharashtra, India\n",
            "(+91) 8087996634 | omkarpathak27@gmail.com |www.omkarpathak.in |OmkarPathak |omkar-pathak-94473811b\n",
            "“Makethechangethatyouwanttoseeintheworld.”\n",
            "Experience\n",
            "Schlumberger Pune,Maharashtra,India\n",
            "DATAENGINEER July2018-Present\n",
            "•Responsibleforimplementingandmanaginganend-to-endCI/CDPipelinewithcustomvalidationsforInformaticamigrationswhich\n",
            "broughtmigrationtimeto1.5hoursfrom9hourswithoutanymanualintervention\n",
            "•Enhancing,auditingandmaintainingcustomdataingestionframeworkthatingestaround1TBofdataeachdaytoover70business\n",
            "units\n",
            "•WorkingwithL3developerteamtoensurethediscussedScrumPBI’saredeliveredontimefordataingestions\n",
            "•PlanningandExecutingQAandProductionReleaseCycleactivities\n",
            "Truso Pune,Maharashtra,India\n",
            "FULLSTACKDEVELOPERINTERN June2018-July2018\n",
            "•CreatedRESTfulapis\n",
            "•TriedmyhandsonAngular5/6\n",
            "•WasresponsibleforDjangobackenddevelopment\n",
            "Propeluss Pune,Maharashtra,India\n",
            "DATAENGINEERINGINTERN October2017-January2018\n",
            "•Wrotevariousautomationscriptstoscrapedatafromvariouswebsites.\n",
            "•Applied Natural Language Processing to articles scraped from the internet to extract different entities in these articles using entity\n",
            "extractionalgorithmsandapplyingMachineLearningtoclassifythesearticles.\n",
            "•AlsoappliedKNNwithLSAforextractingrelevanttagsforvariousstartupsbasedontheirworks.\n",
            "GeeksForGeeks Pune,Maharashtra,India\n",
            "TECHNICALCONTENTWRITER July2017-September2017\n",
            "•Published4articlesforthetopicssuchasDataStructuresandAlgorithmsandPython\n",
            "SofttestlabTechnologies Pune,Maharashtra,India\n",
            "WEBDEVELOPERINTERN June2017-July2017\n",
            "•WasresponsibleforcreatinganinternalprojectforthecompanyusingPHPandLaravelfortestingpurposes\n",
            "•WorkedonaliveprojectforcreatingclosurereportsusingPHPandExcel\n",
            "Projects\n",
            "Pyresparser API/PythonPackage\n",
            "PERSONALPROJECT July2019-Present\n",
            "•Asimpleresumeparserusedforextractinginformationfromresumes\n",
            "•Extractinformationfromthousandsofresumesinjustafewseconds\n",
            "•Authorandmaintainerofthisproject\n",
            "GarbageLevelMonitoringSystem IoT\n",
            "TEAMPROJECT October2017-May2018\n",
            "•Tofindaeconomicalandsmarteralternativetocurrentgarbageproblems\n",
            "•Userscanmonitorlevelsofallgarbagebinsfromaglobaldashboardprovided\n",
            "•WasresponsibleforDjangobackenddevelopment\n",
            "NOVEMBER3,2019 OMKARPATHAK · RÉSUMÉ 1Pygorithm API/PythonPackage\n",
            "PERSONALPROJECT July2017-Present\n",
            "•Authorandmaintainerofthisproject\n",
            "•Aneducationallibrarytoteachallthemajoralgorithms\n",
            "•Gotcoveredin Fosstack,FullStackFeed ,KleiberandTaggedunderHotestGithubProjecton ITCodeMonkey\n",
            "SmartSurveillanceSystemusingRaspberryPiandFaceRecognitionIoT\n",
            "PERSONALPROJECT January2017-February2017\n",
            "•FaceRecognitionusingOpenCVandPython\n",
            "•RaspberryPiwasusedasthedataserver\n",
            "•Usernotifiedifanysuspiciousactivitydetectedinrealtime\n",
            "PasswordStrengthEvaluatorusingMachineLearning MachineLearning\n",
            "PERSONALPROJECT March2017\n",
            "•SVMalgorithmusedfortrainingandclassification\n",
            "•Flaskframeworkused\n",
            "•Self-generateddataset\n",
            "Education\n",
            "MarathwadaMitraMandal’sCollegeofEngineering Pune,Maharashtra,India\n",
            "B.E.INCOMPUTERENGINEERING 2014-2018\n",
            "•Aggregate74%\n",
            "Skills\n",
            "ProgrammingLanguages: Python,C,PHP,C++,ShellScript\n",
            "FrontendTechnologies: HTML,CSS,JavaScript,Angular6/7\n",
            "BackendTechnologies: Django,Flask(Python),Laravel(PHP)\n",
            "OperatingSystems: Linux,Unix,Windows\n",
            "Databases: MySQL,SQLite,MongoDB\n",
            "Other: Git,NLP,Scikit-Learn,OpenCV,Cloud(GCP,Azure,DigitalOcean)\n",
            "Honors&Awards\n",
            "2018TopratedPythondeveloper ,inPuneand FifthinIndiaat Github India\n",
            "2018QuoraTopWriter , India\n",
            "2018Awarded‘TheBestOutgoingStudentAward2017-18’ , MMCOE,Pune\n",
            "2018Won2ndPrize ,inanHackathonorganizedbyMIT-ADTPersonaFest2018 Pune\n",
            "2018BestPaperAward ,inNationalLevelConferenceon“EmergingTrendsinComputing,Analytics\n",
            "andSecurity-2018”(NCETCAS-2018)MMCOE,Pune\n",
            "ExtracurricularActivities\n",
            "ContributorinPunePyCon2018\n",
            "PUNE,MAHARASHTRA,INDIA 2018\n",
            "•WasapartofWebsiteDesigningandvolunteeringcommittee\n",
            "NOVEMBER3,2019 OMKARPATHAK · RÉSUMÉ 2MentoratGirlScriptSummerofCode2019\n",
            "PUNE,MAHARASHTRA,INDIA 2019\n",
            "•Mentored4+teamsinvariousdomains\n",
            "OrganizingheadfortheNationalleveltechnicalevent-\n",
            "Innovatus\n",
            "PUNE,MAHARASHTRA,INDIA 2018\n",
            "•Organizedprojectcompetitions\n",
            "WorkshoponIoTandPython\n",
            "MMCOE,PUNE 10Jan2017\n",
            "•Conductedaworkshop forsecondyearstudentstogivethemabriefoverviewaboutIoTbycompletingthreeminiprojectsandtaught\n",
            "thembasicsofPythonprogramminglanguage\n",
            "Publications\n",
            "SmartSurveillanceSystemusingRaspberryPiandFace\n",
            "RecognitionDOI10.17148/IJARCCE.2017.64117\n",
            "GarbageLevelMonitoringSystem\n",
            "Interests\n",
            "•CompetitiveProgramming\n",
            "•Photography\n",
            "•Sketching\n",
            "•Reading/WritingonQuora\n",
            "•ContributingtoOpenSourceprojects\n",
            "NOVEMBER3,2019 OMKARPATHAK · RÉSUMÉ 3\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "                                         Resume File  Matching Percentage\n",
            "0  SwapnilPratapShingate_Azure ( 3 certification)...                   40\n",
            "1                                    OmkarResume.pdf                    0\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import PyPDF2\n",
        "from langchain.llms import OpenAIChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def extract_text_from_binary(file):\n",
        "    pdf_data = io.BytesIO(file)\n",
        "    reader = PyPDF2.PdfReader(pdf_data)\n",
        "    num_pages = len(reader.pages)\n",
        "    text = \"\"\n",
        "\n",
        "    for page in range(num_pages):\n",
        "        current_page = reader.pages[page]\n",
        "        text += current_page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Define the folder containing resumes\n",
        "# resume_folder_path = '/content/resumes/'\n",
        "resume_folder_path = 'content/resumes/'\n",
        "\n",
        "# Define your job description here\n",
        "template = \"\"\"\n",
        "Compare the following Job Title and Responsibilities with the provided, Display the matching percentage of scores:\n",
        "\n",
        "Context:\n",
        "- In the field of Data Science, it's crucial to have a strong foundation in various algorithms and models.\n",
        "\n",
        "**Job Title:** Data Scientist (Machine Learning)\n",
        "\n",
        "**Responsibilities:**\n",
        "1. Develop and implement machine learning models for data analysis and predictive modeling.\n",
        "2. Collaborate with cross-functional teams to gather and analyze data, ensuring accuracy and relevance.\n",
        "3. Explore and apply advanced statistical techniques to derive actionable insights from large datasets.\n",
        "4. Continuously research and stay updated on the latest advancements in machine learning and data science.\n",
        "5. Communicate findings and recommendations to stakeholders in a clear and understandable manner.\n",
        "\n",
        "Format the answer in below YAML Format:\n",
        "---\n",
        "Total Experience: ''\n",
        "Matching Percentage of Score: ''\n",
        "\n",
        "{human_input}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "        input_variables=[\"human_input\"],\n",
        "        template=template\n",
        "    )\n",
        "\n",
        "# Initialize an empty list to store the results\n",
        "results_list = []\n",
        "\n",
        "# Iterate through all files in the folder\n",
        "for filename in os.listdir(resume_folder_path):\n",
        "    if filename.endswith('.pdf'):\n",
        "        resume_file_path = os.path.join(resume_folder_path, filename)\n",
        "\n",
        "        # Extract text from the resume\n",
        "        with open(resume_file_path, 'rb') as file:\n",
        "            pdf_text = extract_text_from_binary(file.read())\n",
        "\n",
        "        # Create LangChain instance\n",
        "        llm_chain = LLMChain(\n",
        "            llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
        "            prompt=prompt,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "        # Get the result using LangChain\n",
        "        res = llm_chain.predict(human_input=pdf_text)\n",
        "\n",
        "        # Use regular expression to find and extract the score\n",
        "        matching_percentage = re.search(r\"Matching Percentage of Score: '(\\d+)%'\", res)\n",
        "\n",
        "        if matching_percentage:\n",
        "            matching_percentage = int(matching_percentage.group(1))\n",
        "        else:\n",
        "            matching_percentage = None\n",
        "\n",
        "        # Append the result to the list\n",
        "        results_list.append({\n",
        "            'Resume File': filename,\n",
        "            'Matching Percentage': matching_percentage\n",
        "        })\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Print the results DataFrame\n",
        "#results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Replace NaN values with 0\n",
        "results_df['Matching Percentage'].fillna(0, inplace=True)\n",
        "\n",
        "# Print the results DataFrame\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jrXPwHqQ6qAK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Resume File</th>\n",
              "      <th>Matching Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SwapnilPratapShingate_Azure ( 3 certification)...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OmkarResume.pdf</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Resume File  Matching Percentage\n",
              "0  SwapnilPratapShingate_Azure ( 3 certification)...                   40\n",
              "1                                    OmkarResume.pdf                    0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
